{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0897a461",
   "metadata": {},
   "source": [
    "## Data Preparation and Data Cleaning\n",
    "\n",
    "1. **Reshape the data**: The image data in the CIFAR-100 dataset is stored as 1D arrays. We want to reshape it into 3D arrays (32x32x3) for easier processing and analysis.\n",
    "\n",
    "2. **Resize the data**: The image data in the CIFAR-100 dataset is 32x32. To be able to use transfer learning using common pretrained models, the image data has to be resized to a minimum of 75x75.\n",
    "\n",
    "3. **Normalize the data**: The pixel values of the images are in the range [0, 255]. We want to normalize these values to the range [0, 1] for better performance of the machine learning models.\n",
    "\n",
    "4. **Consider only the coarse labels**: For simplicity, We can consider only the 20 \"coarse\" labels (superclasses) rather than the 100 \"fine\" labels (classes) when We train multi-class image classifiers for this dataset. This means We would use `coarse_labels` instead of `fine_labels` in our code.\n",
    "\n",
    "5. **One-hot encode the labels**: The labels are currently integers representing the class of each image. We want to one-hot encode these labels for multi-class classification tasks.\n",
    "\n",
    "6. **Split the data**: The CIFAR-100 dataset comes with predefined train and test sets. We want to further split the train set into a validation set for tuning the hyperparameters of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b40f9a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T04:30:15.784062Z",
     "iopub.status.busy": "2023-12-12T04:30:15.783612Z",
     "iopub.status.idle": "2023-12-12T04:30:19.612768Z",
     "shell.execute_reply": "2023-12-12T04:30:19.612116Z",
     "shell.execute_reply.started": "2023-12-12T04:30:15.784006Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the data\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "# Downsample the data\n",
    "def downsample_data(data, labels, num_samples_per_class):\n",
    "    downsampled_data = []\n",
    "    downsampled_labels = []\n",
    "    for i in range(20):  # 20 superclasses\n",
    "        indices = np.where(labels == i)[0]\n",
    "        downsampled_indices = np.random.choice(indices, num_samples_per_class, replace=False)\n",
    "        downsampled_data.append(data[downsampled_indices])\n",
    "        downsampled_labels.append(labels[downsampled_indices])\n",
    "    return np.concatenate(downsampled_data), np.concatenate(downsampled_labels)\n",
    "\n",
    "# Load the data\n",
    "metadata_path = '../data/cifar-100-python/meta'\n",
    "metadata = unpickle(metadata_path)\n",
    "data_train_path = '../data/cifar-100-python/train'\n",
    "data_test_path = '../data/cifar-100-python/test'\n",
    "data_train_dict = unpickle(data_train_path)\n",
    "data_test_dict = unpickle(data_test_path)\n",
    "\n",
    "# Downsample the data\n",
    "data_train, label_train = downsample_data(data_train_dict[b'data'], np.array(data_train_dict[b'coarse_labels']), 500)\n",
    "data_test, label_test = downsample_data(data_test_dict[b'data'], np.array(data_test_dict[b'coarse_labels']), 100)\n",
    "\n",
    "# Reshape the data\n",
    "data_train = data_train.reshape((data_train.shape[0], 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "data_test = data_test.reshape((data_test.shape[0], 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "\n",
    "# Resize the data to (75, 75)\n",
    "data_train = tf.image.resize(data_train, [75, 75])\n",
    "data_test = tf.image.resize(data_test, [75, 75])\n",
    "\n",
    "# Normalize the data\n",
    "data_train = data_train.numpy().astype('float32') / 255\n",
    "data_test = data_test.numpy().astype('float32') / 255\n",
    "\n",
    "# One-hot encode the labels\n",
    "label_train = to_categorical(label_train, 20)\n",
    "label_test = to_categorical(label_test, 20)\n",
    "\n",
    "# Split the data into train and validate sets\n",
    "data_train, data_validate, label_train, label_validate = train_test_split(data_train, label_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save the cleaned and processed data\n",
    "os.makedirs('../data/clean-all-cifar-100-python/train', exist_ok=True)\n",
    "os.makedirs('../data/clean-all-cifar-100-python/validate', exist_ok=True)\n",
    "os.makedirs('../data/clean-all-cifar-100-python/test', exist_ok=True)\n",
    "np.save('../data/clean-all-cifar-100-python/train/data.npy', data_train)\n",
    "np.save('../data/clean-all-cifar-100-python/train/labels.npy', label_train)\n",
    "np.save('../data/clean-all-cifar-100-python/validate/data.npy', data_validate)\n",
    "np.save('../data/clean-all-cifar-100-python/validate/labels.npy', label_validate)\n",
    "np.save('../data/clean-all-cifar-100-python/test/data.npy', data_test)\n",
    "np.save('../data/clean-all-cifar-100-python/test/labels.npy', label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a9dbc3",
   "metadata": {},
   "source": [
    "## EDA (Exploratory Data Analysis), Feature Importance Analysis\n",
    "\n",
    "1. **Visualize the images**: Display some sample images from each class to get a sense of what the images look like.\n",
    "\n",
    "2. **Class distribution**: Check the distribution of the classes in the train and test sets. If the classes are imbalanced, We need to take this into account when training our models.\n",
    "\n",
    "3. **Feature importance**: In the context of image data, feature importance analysis might involve using techniques like occlusion sensitivity to understand which parts of the images are most important for the predictions of a trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a315200",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T04:30:19.615373Z",
     "iopub.status.busy": "2023-12-12T04:30:19.614791Z",
     "iopub.status.idle": "2023-12-12T04:30:24.372131Z",
     "shell.execute_reply": "2023-12-12T04:30:24.371427Z",
     "shell.execute_reply.started": "2023-12-12T04:30:19.615337Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load the data\n",
    "def load_data(folder):\n",
    "    data = np.load(os.path.join(folder, 'data.npy'))\n",
    "    labels = np.load(os.path.join(folder, 'labels.npy'))\n",
    "    return data, labels\n",
    "\n",
    "# Visualize the images\n",
    "def visualize_images(data, labels, num_images_per_class):\n",
    "    fig, axs = plt.subplots(20, num_images_per_class, figsize=(5, 10))  # 20 superclasses\n",
    "    for i in range(20):  # For each superclass\n",
    "        indices = np.where(np.argmax(labels, axis=1) == i)[0]\n",
    "        random_indices = np.random.choice(indices, num_images_per_class, replace=False)\n",
    "        for j, image_index in enumerate(random_indices):\n",
    "            image = data[image_index]\n",
    "            axs[i, j].imshow(image, interpolation='bicubic')\n",
    "            axs[i, j].axis('off')  # Hide axes\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.show()\n",
    "\n",
    "# Check the class distribution\n",
    "def check_class_distribution(labels):\n",
    "    class_distribution = np.sum(labels, axis=0)\n",
    "    print(\"Class distribution:\", class_distribution)\n",
    "\n",
    "# Load the data\n",
    "data_train, label_train = load_data('../data/clean-all-cifar-100-python/train')\n",
    "data_test, label_test = load_data('../data/clean-all-cifar-100-python/test')\n",
    "\n",
    "# Visualize the images\n",
    "visualize_images(data_train, label_train, 10)\n",
    "\n",
    "# Check the class distribution\n",
    "check_class_distribution(label_train)\n",
    "check_class_distribution(label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e979fa74",
   "metadata": {},
   "source": [
    "## Model Selection Process and Parameter Tuning\n",
    "\n",
    "1. **Choose a model architecture**: For image classification tasks, convolutional neural networks (CNNs) are usually a good choice. We want to experiment with three different architectures (Xception, ResNet50, DenseNet121) to see which one works best for this dataset.\n",
    "\n",
    "2. **Hyperparameter tuning**: Tune the hyperparameters of our model (learning rate, batch size, number of layers) to optimize its performance.\n",
    "\n",
    "3. **Regularization**: To prevent overfitting, We want to use regularization techniques like dropout.\n",
    "\n",
    "4. **Model training**: Train our model using the train set and monitor its performance on the validation set. We can use techniques like early stopping to prevent overfitting.\n",
    "\n",
    "5. **Model evaluation**: Evaluate the performance of our model on the test set using appropriate metrics (e.g., accuracy, precision, recall, F1 score)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcde9cd",
   "metadata": {},
   "source": [
    "### A) Model Architecture: Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00b31c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T04:52:26.769899Z",
     "iopub.status.busy": "2023-12-12T04:52:26.769535Z",
     "iopub.status.idle": "2023-12-12T04:55:52.781528Z",
     "shell.execute_reply": "2023-12-12T04:55:52.780701Z",
     "shell.execute_reply.started": "2023-12-12T04:52:26.769873Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Load the data\n",
    "def load_data(folder):\n",
    "    data = np.load(os.path.join(folder, 'data.npy'))\n",
    "    labels = np.load(os.path.join(folder, 'labels.npy'))\n",
    "    return data, labels\n",
    "\n",
    "# Define the model\n",
    "def make_model(learning_rate=0.01, size_inner=10, droprate=0.0):\n",
    "    base_model = Xception(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(75, 75, 3)  # Use the resized image size 75x75\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "    inputs = keras.Input(shape=(75, 75, 3))\n",
    "    base = base_model(inputs, training=False)\n",
    "    vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "    vectors = Dropout(droprate)(vectors)  # Add dropout\n",
    "    vectors = keras.layers.Dense(size_inner, activation='relu')(vectors)  # Adjust the size of inner layer\n",
    "    outputs = keras.layers.Dense(20)(vectors)  # Use 20 superclasses\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Load the data\n",
    "data_train, label_train = load_data('../data/clean-all-cifar-100-python/train')\n",
    "data_test, label_test = load_data('../data/clean-all-cifar-100-python/validate')\n",
    "\n",
    "# Fine-tune the learning rate\n",
    "best_val_accuracy = 0\n",
    "best_lr = 0\n",
    "scores = {}\n",
    "for lr in [0.0001, 0.001, 0.01, 0.1]:\n",
    "    print(lr)\n",
    "    model = make_model(learning_rate=lr)\n",
    "    history = model.fit(data_train, label_train, epochs=10, validation_data=(data_test, label_test))\n",
    "    scores[lr] = history.history\n",
    "    if max(history.history['val_accuracy']) > best_val_accuracy:\n",
    "        best_val_accuracy = max(history.history['val_accuracy'])\n",
    "        best_lr = lr\n",
    "\n",
    "for lr, hist in scores.items():\n",
    "    plt.plot(hist['val_accuracy'], label=('val=%s' % lr))\n",
    "plt.title('Validation Accuracy for the Learning Rate')\n",
    "plt.xticks(np.arange(10))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Fine-tune the size_inner parameter\n",
    "best_val_accuracy = 0\n",
    "best_size = 0\n",
    "scores = {}\n",
    "for size in [10, 100, 1000]:\n",
    "    print(size)\n",
    "    model = make_model(learning_rate=best_lr, size_inner=size)\n",
    "    history = model.fit(data_train, label_train, epochs=10, validation_data=(data_test, label_test))\n",
    "    scores[size] = history.history\n",
    "    if max(history.history['val_accuracy']) > best_val_accuracy:\n",
    "        best_val_accuracy = max(history.history['val_accuracy'])\n",
    "        best_size = size\n",
    "\n",
    "for size, hist in scores.items():\n",
    "    plt.plot(hist['val_accuracy'], label=('val=%s' % size))\n",
    "plt.title('Validation Accuracy for the size_inner Parameter')\n",
    "plt.xticks(np.arange(10))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "        \n",
    "# Fine-tune the dropout rate\n",
    "best_val_accuracy = 0\n",
    "best_droprate = 0\n",
    "scores = {}\n",
    "for droprate in [0.0, 0.2, 0.5, 0.8]:\n",
    "    print(droprate)\n",
    "    model = make_model(learning_rate=best_lr, size_inner=best_size, droprate=droprate)\n",
    "    history = model.fit(data_train, label_train, epochs=10, validation_data=(data_test, label_test))\n",
    "    scores[droprate] = history.history\n",
    "    if max(history.history['val_accuracy']) > best_val_accuracy:\n",
    "        best_val_accuracy = max(history.history['val_accuracy'])\n",
    "        best_droprate = droprate\n",
    "\n",
    "for droprate, hist in scores.items():\n",
    "    plt.plot(hist['val_accuracy'], label=('val=%s' % droprate))\n",
    "plt.title('Validation Accuracy for the Dropout Rate')\n",
    "plt.xticks(np.arange(10))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "        \n",
    "# Save the best model using callbacks and checkpointing\n",
    "model = make_model(learning_rate=best_lr, size_inner=best_size, droprate=best_droprate)\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'xception_v1_{epoch:02d}_{val_accuracy:.3f}.h5',\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max'\n",
    ")\n",
    "history = model.fit(\n",
    "    data_train,\n",
    "    label_train,\n",
    "    epochs=10,\n",
    "    validation_data=(data_test, label_test),\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a592b15e",
   "metadata": {},
   "source": [
    "### B) Model Architecture: ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2a4699",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T04:58:20.618215Z",
     "iopub.status.busy": "2023-12-12T04:58:20.617842Z",
     "iopub.status.idle": "2023-12-12T05:01:57.264162Z",
     "shell.execute_reply": "2023-12-12T05:01:57.263534Z",
     "shell.execute_reply.started": "2023-12-12T04:58:20.618188Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Load the data\n",
    "def load_data(folder):\n",
    "    data = np.load(os.path.join(folder, 'data.npy'))\n",
    "    labels = np.load(os.path.join(folder, 'labels.npy'))\n",
    "    return data, labels\n",
    "\n",
    "# Define the model\n",
    "def make_model(learning_rate=0.01, size_inner=10, droprate=0.0):\n",
    "    base_model = ResNet50(  # Use ResNet50\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(75, 75, 3)  # Use the resized image size 75x75\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "    inputs = keras.Input(shape=(75, 75, 3))\n",
    "    base = base_model(inputs, training=False)\n",
    "    vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "    vectors = Dropout(droprate)(vectors)  # Add dropout\n",
    "    vectors = keras.layers.Dense(size_inner, activation='relu')(vectors)  # Adjust the size of inner layer\n",
    "    outputs = keras.layers.Dense(20)(vectors)  # Use 20 superclasses\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Load the data\n",
    "data_train, label_train = load_data('../data/clean-all-cifar-100-python/train')\n",
    "data_test, label_test = load_data('../data/clean-all-cifar-100-python/validate')\n",
    "\n",
    "# Fine-tune the learning rate\n",
    "best_val_accuracy = 0\n",
    "best_lr = 0\n",
    "scores = {}\n",
    "for lr in [0.0001, 0.001, 0.01, 0.1]:\n",
    "    print(lr)\n",
    "    model = make_model(learning_rate=lr)\n",
    "    history = model.fit(data_train, label_train, epochs=10, validation_data=(data_test, label_test))\n",
    "    scores[lr] = history.history\n",
    "    if max(history.history['val_accuracy']) > best_val_accuracy:\n",
    "        best_val_accuracy = max(history.history['val_accuracy'])\n",
    "        best_lr = lr\n",
    "\n",
    "for lr, hist in scores.items():\n",
    "    plt.plot(hist['val_accuracy'], label=('val=%s' % lr))\n",
    "plt.title('Validation Accuracy for the Learning Rate')\n",
    "plt.xticks(np.arange(10))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Fine-tune the size_inner parameter\n",
    "best_val_accuracy = 0\n",
    "best_size = 0\n",
    "scores = {}\n",
    "for size in [10, 100, 1000]:\n",
    "    print(size)\n",
    "    model = make_model(learning_rate=best_lr, size_inner=size)\n",
    "    history = model.fit(data_train, label_train, epochs=10, validation_data=(data_test, label_test))\n",
    "    scores[size] = history.history\n",
    "    if max(history.history['val_accuracy']) > best_val_accuracy:\n",
    "        best_val_accuracy = max(history.history['val_accuracy'])\n",
    "        best_size = size\n",
    "\n",
    "for size, hist in scores.items():\n",
    "    plt.plot(hist['val_accuracy'], label=('val=%s' % size))\n",
    "plt.title('Validation Accuracy for the size_inner Parameter')\n",
    "plt.xticks(np.arange(10))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "        \n",
    "# Fine-tune the dropout rate\n",
    "best_val_accuracy = 0\n",
    "best_droprate = 0\n",
    "scores = {}\n",
    "for droprate in [0.0, 0.2, 0.5, 0.8]:\n",
    "    print(droprate)\n",
    "    model = make_model(learning_rate=best_lr, size_inner=best_size, droprate=droprate)\n",
    "    history = model.fit(data_train, label_train, epochs=10, validation_data=(data_test, label_test))\n",
    "    scores[droprate] = history.history\n",
    "    if max(history.history['val_accuracy']) > best_val_accuracy:\n",
    "        best_val_accuracy = max(history.history['val_accuracy'])\n",
    "        best_droprate = droprate\n",
    "\n",
    "for droprate, hist in scores.items():\n",
    "    plt.plot(hist['val_accuracy'], label=('val=%s' % droprate))\n",
    "plt.title('Validation Accuracy for the Dropout Rate')\n",
    "plt.xticks(np.arange(10))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Save the best model using callbacks and checkpointing\n",
    "model = make_model(learning_rate=best_lr, size_inner=best_size, droprate=best_droprate)\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'resnet50_v1_{epoch:02d}_{val_accuracy:.3f}.h5',  # Change the filename to reflect the use of ResNet50\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max'\n",
    ")\n",
    "history = model.fit(\n",
    "    data_train,\n",
    "    label_train,\n",
    "    epochs=10,\n",
    "    validation_data=(data_test, label_test),\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86c76ad",
   "metadata": {},
   "source": [
    "### C) Model Architecture: DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0444e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T05:06:46.317581Z",
     "iopub.status.busy": "2023-12-12T05:06:46.317204Z",
     "iopub.status.idle": "2023-12-12T05:19:34.176695Z",
     "shell.execute_reply": "2023-12-12T05:19:34.176076Z",
     "shell.execute_reply.started": "2023-12-12T05:06:46.317556Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.densenet import DenseNet121 \n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Load the data\n",
    "def load_data(folder):\n",
    "    data = np.load(os.path.join(folder, 'data.npy'))\n",
    "    labels = np.load(os.path.join(folder, 'labels.npy'))\n",
    "    return data, labels\n",
    "\n",
    "# Define the model\n",
    "def make_model(learning_rate=0.01, size_inner=10, droprate=0.0):\n",
    "    base_model = DenseNet121(  # Use DenseNet121 instead of ResNet50\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(75, 75, 3)  # Use the resized image size 75x75\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "    inputs = keras.Input(shape=(75, 75, 3))\n",
    "    base = base_model(inputs, training=False)\n",
    "    vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "    vectors = Dropout(droprate)(vectors)  # Add dropout\n",
    "    vectors = keras.layers.Dense(size_inner, activation='relu')(vectors)  # Adjust the size of inner layer\n",
    "    outputs = keras.layers.Dense(20)(vectors)  # Use 20 superclasses\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Load the data\n",
    "data_train, label_train = load_data('../data/clean-all-cifar-100-python/train')\n",
    "data_test, label_test = load_data('../data/clean-all-cifar-100-python/validate')\n",
    "\n",
    "# Fine-tune the learning rate\n",
    "best_val_accuracy = 0\n",
    "best_lr = 0\n",
    "scores = {}\n",
    "for lr in [0.0001, 0.001, 0.01, 0.1]:\n",
    "    print(lr)\n",
    "    model = make_model(learning_rate=lr)\n",
    "    history = model.fit(data_train, label_train, epochs=50, validation_data=(data_test, label_test))\n",
    "    scores[lr] = history.history\n",
    "    if max(history.history['val_accuracy']) > best_val_accuracy:\n",
    "        best_val_accuracy = max(history.history['val_accuracy'])\n",
    "        best_lr = lr\n",
    "\n",
    "for lr, hist in scores.items():\n",
    "    plt.plot(hist['val_accuracy'], label=('val=%s' % lr))\n",
    "plt.title('Validation Accuracy for the Learning Rate')\n",
    "plt.xticks(np.arange(10))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Fine-tune the size_inner parameter\n",
    "best_val_accuracy = 0\n",
    "best_size = 0\n",
    "scores = {}\n",
    "for size in [10, 100, 1000]:\n",
    "    print(size)\n",
    "    model = make_model(learning_rate=best_lr, size_inner=size)\n",
    "    history = model.fit(data_train, label_train, epochs=50, validation_data=(data_test, label_test))\n",
    "    scores[size] = history.history\n",
    "    if max(history.history['val_accuracy']) > best_val_accuracy:\n",
    "        best_val_accuracy = max(history.history['val_accuracy'])\n",
    "        best_size = size\n",
    "\n",
    "for size, hist in scores.items():\n",
    "    plt.plot(hist['val_accuracy'], label=('val=%s' % size))\n",
    "plt.title('Validation Accuracy for the size_inner Parameter')\n",
    "plt.xticks(np.arange(10))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "        \n",
    "# Fine-tune the dropout rate\n",
    "best_val_accuracy = 0\n",
    "best_droprate = 0\n",
    "scores = {}\n",
    "for droprate in [0.0, 0.2, 0.5, 0.8]:\n",
    "    print(droprate)\n",
    "    model = make_model(learning_rate=best_lr, size_inner=best_size, droprate=droprate)\n",
    "    history = model.fit(data_train, label_train, epochs=50, validation_data=(data_test, label_test))\n",
    "    scores[droprate] = history.history\n",
    "    if max(history.history['val_accuracy']) > best_val_accuracy:\n",
    "        best_val_accuracy = max(history.history['val_accuracy'])\n",
    "        best_droprate = droprate\n",
    "\n",
    "for droprate, hist in scores.items():\n",
    "    plt.plot(hist['val_accuracy'], label=('val=%s' % droprate))\n",
    "plt.title('Validation Accuracy for the Dropout Rate')\n",
    "plt.xticks(np.arange(10))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Save the best model using callbacks and checkpointing\n",
    "model = make_model(learning_rate=best_lr, size_inner=best_size, droprate=best_droprate)\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'densenet121_v1_{epoch:02d}_{val_accuracy:.3f}.h5',  # Change the filename to reflect the use of DenseNet121\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max'\n",
    ")\n",
    "history = model.fit(\n",
    "    data_train,\n",
    "    label_train,\n",
    "    epochs=50,\n",
    "    validation_data=(data_test, label_test),\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62aba603",
   "metadata": {},
   "source": [
    "### D) Best Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3139f2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T05:21:44.171043Z",
     "iopub.status.busy": "2023-12-12T05:21:44.170653Z",
     "iopub.status.idle": "2023-12-12T05:21:58.109555Z",
     "shell.execute_reply": "2023-12-12T05:21:58.108814Z",
     "shell.execute_reply.started": "2023-12-12T05:21:44.171016Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "def load_data(folder):\n",
    "    data = np.load(os.path.join(folder, 'data.npy'))\n",
    "    labels = np.load(os.path.join(folder, 'labels.npy'))\n",
    "    return data, labels\n",
    "\n",
    "# Load the test data\n",
    "data_test, label_test = load_data('../data/clean-all-cifar-100-python/test')\n",
    "\n",
    "# Define the model names\n",
    "model_names = ['xception_v1_10_0.522.h5', \n",
    "               'resnet50_v1_08_0.117.h5', \n",
    "               'densenet121_v1_38_0.515.h5']\n",
    "\n",
    "# Initialize a dictionary to store the metrics\n",
    "metrics = {}\n",
    "\n",
    "# For each model\n",
    "for model_name in model_names:\n",
    "    # Load the model\n",
    "    model = load_model(model_name)\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(data_test, label_test, verbose=0)\n",
    "    # Predict the classes\n",
    "    y_pred = model.predict(data_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true_classes = np.argmax(label_test, axis=1)\n",
    "    # Calculate precision, recall, and F1 score\n",
    "    classification_metrics = classification_report(y_true_classes, y_pred_classes, output_dict=True)\n",
    "    precision = classification_metrics['weighted avg']['precision']\n",
    "    recall = classification_metrics['weighted avg']['recall']\n",
    "    f1_score = classification_metrics['weighted avg']['f1-score']\n",
    "    # Store the metrics\n",
    "    metrics[model_name] = {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1_score': f1_score}\n",
    "\n",
    "# Plot the metrics\n",
    "plt.figure(figsize=(10, 6))\n",
    "for model_name, model_metrics in metrics.items():\n",
    "    plt.plot(list(model_metrics.values()), label=model_name)\n",
    "plt.xticks(np.arange(4), ['accuracy', 'precision', 'recall', 'f1_score'])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2804b1a0",
   "metadata": {},
   "source": [
    "### E) Final Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd61b561",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T05:23:28.827132Z",
     "iopub.status.busy": "2023-12-12T05:23:28.826725Z",
     "iopub.status.idle": "2023-12-12T05:23:28.831176Z",
     "shell.execute_reply": "2023-12-12T05:23:28.830426Z",
     "shell.execute_reply.started": "2023-12-12T05:23:28.827099Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The name of the best model based on the Best Model Comparison\n",
    "print(\"densenet121_v1_38_0.515.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0b98f1-5830-478d-a3c5-4362bab52797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
